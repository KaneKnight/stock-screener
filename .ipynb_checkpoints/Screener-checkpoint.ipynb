{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Screener\n",
    "\n",
    "### This notebook is intended to help get a centralized view of important statistics for stocks of companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports\n",
    "We begin with all the imports we will need for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Getting tickers for gold stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEM', 'ABX', 'FNV.TO', 'NCM.AX', 'GG', 'AEM', 'KGC', 'RGLD', 'RRS.L', 'FRES.L', 'AGG.AX', 'EVN.AX', 'GFI', 'BTO.TO', 'YRI.TO', 'IMG.TO', 'AGI.TO', 'CEY.L', 'PVG', 'DGC.TO', 'NGD.TO', 'RRL.AX', 'OGC.TO', 'SBM.AX', 'CG.TO', 'EDV.TO', 'NG.TO', 'ELD.TO', 'SAR.AX', 'SMF.TO', 'HMY', 'TXG.TO', 'CGG.TO', 'NSU.TO', 'GUY.TO', 'RSG.AX', 'SEA.TO', 'MUX', 'RIC', 'PG.TO', 'OSK.TO', 'ALIAF', 'CNL.TO', 'GOR.AX', 'POG.L', 'GSS', 'PAF.L', 'AR.TO', 'PRU.AX', 'TBR.AX', 'BGM.V', 'TGZ.TO', 'SBB.TO', 'GORO', 'WDO.TO', 'HRT.TO', 'WAF.AX', 'VIT.V', 'AOT.V', 'NGQ.TO', 'BDR.AX', 'HUM.L', 'RMS.AX', 'SLR.AX', 'BSX.TO', 'GCY.AX', 'KOR.TO', 'MOZ.TO', 'BTR.V', 'HRR.AX', 'PRB.V', 'ALK.AX', 'HAS.AX', 'R.TO', 'JAG.TO', 'MAX.TO', 'TNG.AX', 'PEN.AX', 'CAL.TO', 'TLG.AX', 'RUP.V', 'GGP.L', 'AAL.V', 'KCN.AX', 'ITH.TO', 'MML.AX', 'GGG.AX', 'VGZ', 'ARU.V', 'RMX.TO', 'QBL.AX', 'TSG.L', 'ATC.V', 'KGL.AX', 'TML.TO', 'IMA.AX', 'DRM.AX', 'RED.AX', 'MTO.V', 'DGR.AX', 'MRC.AX', 'DNG.TO', 'LIO.V', 'GME.AX', 'LEG.AX', 'BAR.TO', 'ATM.V', 'EAR.AX', 'KRM.AX', 'FML.AX', 'ORN.AX', 'ER.TO', 'RGD.V', 'RBX.V', 'LYD.TO', 'TXR.V', 'DEG.AX', 'TAM.AX', 'NGY.AX', 'CHN.AX', 'GRR.V', 'LG.V', 'GSR.V', 'TRY.AX', 'TNX.TO', 'TLM.AX', 'ME.TO', 'MJS.V', 'GCM.TO', 'BSR.AX', 'RTG.TO', 'CAY.AX', 'KTN.V', 'MRP.AX', 'ARE.AX', 'FSY.TO', 'TON.AX', 'SRB.L', 'BCN.AX', 'TSG.V', 'MAT.AX', 'IRC.AX', 'ERM.AX', 'ORV.TO', 'HMX.V', 'NGE.V', 'SPA.V', 'MAW.TO', 'MNR.TO', 'ANX.TO', 'SKE.V', 'AAU.L', 'WHY.V', 'NAG.AX', 'GRG.V', 'GQC.V', 'AAR.AX', 'AGC.V', 'HAW.AX', 'RUG.V', 'ECR.V', 'SIH.AX', 'SMC.AX', 'GLN.AX', 'GQM.TO', 'GDP.L', 'SAU.TO', 'MMV.V', 'GAL.V', 'MMY.V', 'CAS.AX', 'LPK.V', 'GWR.AX', 'REX.V', 'CLH.V', 'KG.V', 'AAB.TO', 'IAU.AX', 'AGG.V', 'BAR.AX', 'DRA.AX', 'OGR.V', 'AGD.V', 'DGO.AX', 'WDG.V', 'WKM.V', 'ANK.V', 'AZX.V', 'RRI.V', 'GWA.V', 'MC.V', 'BRZ.V', 'JPR.AX', 'CRB.AX', 'SWA.V', 'PJX.V', 'OOO.V', 'AZM.AX', 'AOM.AX', 'RDS.V', 'MUN.V', 'MDI.AX', 'MAE.V', 'TEN.V', 'HLX.AX', 'AGS.AX', 'LME.V', 'CTM.AX', 'RPX.V', 'MSR.AX', 'BAT.V', 'CTO.AX', 'MTU.V', 'RG.V', 'ECC.V', 'IO.V', 'GGA.TO']\n"
     ]
    }
   ],
   "source": [
    "#Where tickers comes from\n",
    "goldStocksUrl = \"http://www.miningfeeds.com/gold-mining-report-all-countries\"\n",
    "\n",
    "def goldStockParser(url, tickerColumn, stockTypes):\n",
    "    \"\"\"Goes to url above and pulls the tickers of each \n",
    "       gold mining company, dumps them in a pickle file \n",
    "       and returns the tickers as a list.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    table = soup.find(\"table\")\n",
    "    tickers = []\n",
    "    for row in table.findAll(\"tr\")[1:]:\n",
    "        ticker = row.findAll(\"td\")[tickerColumn].text\n",
    "        #Randgold real ticker.\n",
    "        if (ticker == \"GOLD.L\"):\n",
    "            ticker = \"GOLD\"\n",
    "        tickers.append(ticker)\n",
    "\n",
    "    with open(stockTypes + \".pickle\", \"wb\") as file:\n",
    "        pickle.dump(tickers, file)\n",
    "\n",
    "    return tickers\n",
    "\n",
    "def pickleLoader(stockTypes):\n",
    "    \"\"\"Loads tickers from a pickle file and returns them as a list.\"\"\"\n",
    "    with open(stockTypes + \".pickle\", \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "#Look in cache if False, go to website if true.    \n",
    "reloadGoldTickers = False\n",
    "\n",
    "badDataStocks = [\"GLF.AX\", \"AZ.TO\", \"LEX.TO\", \"RN.TO\", \"P.TO\", \"CSQ.V\",\n",
    "                 \"DNA.TO\", \"PRH.AX\", \"GBU.TO\", \"RPM.V\", \"ARZ.TO\", \"ABU.AX\",\n",
    "                 \"BAA.TO\",]\n",
    "goldStockTickers = []\n",
    "\n",
    "if reloadGoldTickers:\n",
    "    goldStockTickers = goldStockParser(goldStocksUrl, 2, \"goldStocks\")\n",
    "else:\n",
    "    goldStockTickers = pickleLoader(\"goldStocks\")\n",
    "\n",
    "#Remove stocks with bad data.    \n",
    "for ticker in badDataStocks:\n",
    "    goldStockTickers.remove(ticker)\n",
    "    \n",
    "print(goldStockTickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Specify formatting details of data.\n",
    "\n",
    "Specify rows of data that are wanted from yahoo.\n",
    "\n",
    "Specify rows of data that have letters in their numbers for conversion.\n",
    "\n",
    "Specify rows of data that have percentage signs in their numbers for conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wantedRows = {0  : \"marketCap\", \n",
    "              1  : \"enterpriseValue\",\n",
    "              2  : \"trailingPe\",\n",
    "              3  : \"forwardPe\",\n",
    "              4  : \"5YrPeg\",\n",
    "              5  : \"priceSales\",\n",
    "              6  : \"priceBook\",\n",
    "              7  : \"evSales\",\n",
    "              8  : \"evEBITDA\",\n",
    "              11 : \"profitMargin\",\n",
    "              12 : \"operatingMargin\",\n",
    "              13 : \"returnOnAssets\",\n",
    "              14 : \"returnOnEquity\",\n",
    "              15 : \"revenue\",\n",
    "              16 : \"revenuePerShare\",\n",
    "              17 : \"quarterlyRevenueGrowth\",\n",
    "              18 : \"grossProfit\",\n",
    "              19 : \"EBITDA\",\n",
    "              20 : \"netIncomeForCommon\",\n",
    "              21 : \"Diluted EPS\",\n",
    "              22 : \"quarterlyEarningsGrowth\",\n",
    "              23 : \"totalCash\",\n",
    "              24 : \"cashPerShare\",\n",
    "              25 : \"totalDebt\",\n",
    "              26 : \"debtEquity\",\n",
    "              27 : \"currentRatio\",\n",
    "              28 : \"bookValuePerShare\", \n",
    "              29 : \"operatingCashFlow\",\n",
    "              30 : \"leveredFreeCashFlow\",\n",
    "              31 : \"beta3YrMonthly\",\n",
    "              32 : \"52WeekChange\",\n",
    "              33 : \"spy52WeekChange\",\n",
    "              34 : \"52WeekHigh\",\n",
    "              35 : \"52WeekLow\",\n",
    "              36 : \"50dayMvAvg\",\n",
    "              37 : \"200dayMvAvg\",\n",
    "              38 : \"avg3MonthVol\",\n",
    "              39 : \"avg10DayVol\",\n",
    "              40 : \"sharesOutstanding\",\n",
    "              41 : \"sharesFloating\",\n",
    "              42 : \"heldByInsiders\",\n",
    "              43 : \"heldByInstitutions\",\n",
    "              44 : \"sharesShort1MonthPrior\",\n",
    "              45 : \"shortRatio\",\n",
    "              46 : \"shortToFloat\",\n",
    "              47 : \"shortToOutstanding\",\n",
    "              48 : \"sharesShort2MonthsPrior\",\n",
    "              49 : \"forwardDividendRate\",\n",
    "              50 : \"forwardDividendYield\",\n",
    "              51 : \"trailingDividendRate\",\n",
    "              52 : \"trailingDividendYield\",\n",
    "              53 : \"5yrAvgDividendYield\",\n",
    "              54 : \"payoutRatio\",\n",
    "              55 : \"dividendDate\",\n",
    "              56 : \"exDividendDate\",\n",
    "              57 : \"lastSplitFactorNewPerOld\",\n",
    "              58 : \"lastSplitDate\",\n",
    "              60 : \"currentPrice\",}\n",
    "\n",
    "letterNumbers = [\"marketCap\", \n",
    "                 \"enterpriseValue\",\n",
    "                 \"revenue\",\n",
    "                 \"grossProfit\",\n",
    "                 \"EBITDA\",\n",
    "                 \"netIncomeForCommon\",\n",
    "                 \"totalCash\",\n",
    "                 \"totalDebt\",\n",
    "                 \"operatingCashFlow\",\n",
    "                 \"leveredFreeCashFlow\",\n",
    "                 \"avg3MonthVol\",\n",
    "                 \"avg10DayVol\",\n",
    "                 \"sharesOutstanding\",\n",
    "                 \"sharesFloating\",\n",
    "                 \"sharesShort1MonthPrior\",\n",
    "                 \"sharesShort2MonthsPrior\",]\n",
    "\n",
    "percentageNumbers = [\"profitMargin\",\n",
    "                     \"operatingMargin\",\n",
    "                     \"returnOnAssets\",\n",
    "                     \"returnOnEquity\",\n",
    "                     \"quarterlyRevenueGrowth\",\n",
    "                     \"quarterlyEarningsGrowth\"\n",
    "                     \"52WeekChange\",\n",
    "                     \"spy52WeekChange\",\n",
    "                     \"heldByInsiders\",\n",
    "                     \"heldByInstitutions\",\n",
    "                     \"shortToFloat\",\n",
    "                     \"shortToOutstanding\",\n",
    "                     \"forwardDividendYield\",\n",
    "                     \"trailingDividendYield\",\n",
    "                     \"payoutRatio\",]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Retreive data from yahoo and cache it.\n",
    "We need to look up data from yahoo and store it in a csv locally for caching purposes. Also want to format well. ie remove redundant columns and rename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have NEM\n",
      "Already have ABX\n",
      "Already have FNV.TO\n",
      "Already have NCM.AX\n",
      "Already have GG\n",
      "Already have AEM\n",
      "Already have KGC\n",
      "Already have RGLD\n",
      "Already have RRS.L\n",
      "Already have FRES.L\n",
      "Already have AGG.AX\n",
      "Already have EVN.AX\n",
      "Already have GFI\n",
      "Already have BTO.TO\n",
      "Already have YRI.TO\n",
      "Already have IMG.TO\n",
      "Already have AGI.TO\n",
      "Already have CEY.L\n",
      "Already have PVG\n",
      "Already have DGC.TO\n",
      "Already have NGD.TO\n",
      "Already have RRL.AX\n",
      "Already have OGC.TO\n",
      "Already have SBM.AX\n",
      "Already have CG.TO\n",
      "Already have EDV.TO\n",
      "Already have NG.TO\n",
      "Already have ELD.TO\n",
      "Already have SAR.AX\n",
      "Already have SMF.TO\n",
      "Already have HMY\n",
      "Already have TXG.TO\n",
      "Already have CGG.TO\n",
      "Already have NSU.TO\n",
      "Already have GUY.TO\n",
      "Already have RSG.AX\n",
      "Already have SEA.TO\n",
      "Already have MUX\n",
      "Already have RIC\n",
      "Already have PG.TO\n",
      "Already have OSK.TO\n",
      "Already have ALIAF\n",
      "Already have CNL.TO\n",
      "Already have GOR.AX\n",
      "Already have POG.L\n",
      "Already have GSS\n",
      "Already have PAF.L\n",
      "Already have AR.TO\n",
      "Already have PRU.AX\n",
      "Already have TBR.AX\n",
      "Already have BGM.V\n",
      "Already have TGZ.TO\n",
      "Already have SBB.TO\n",
      "Already have GORO\n",
      "Already have WDO.TO\n",
      "Already have HRT.TO\n",
      "Already have WAF.AX\n",
      "Already have VIT.V\n",
      "Already have AOT.V\n",
      "Already have NGQ.TO\n",
      "Already have BDR.AX\n",
      "Already have HUM.L\n",
      "Already have RMS.AX\n",
      "Already have SLR.AX\n",
      "Already have BSX.TO\n",
      "Already have GCY.AX\n",
      "Already have KOR.TO\n",
      "Already have MOZ.TO\n",
      "Already have BTR.V\n",
      "Already have HRR.AX\n",
      "Already have PRB.V\n",
      "Already have ALK.AX\n",
      "Already have HAS.AX\n",
      "Already have R.TO\n",
      "Already have JAG.TO\n",
      "Already have MAX.TO\n",
      "Already have TNG.AX\n",
      "Already have PEN.AX\n",
      "Already have CAL.TO\n",
      "Already have TLG.AX\n",
      "Already have RUP.V\n",
      "Already have GGP.L\n",
      "Already have AAL.V\n",
      "Already have KCN.AX\n",
      "Already have ITH.TO\n",
      "Already have MML.AX\n",
      "Already have GGG.AX\n",
      "Already have VGZ\n",
      "Already have ARU.V\n",
      "Already have RMX.TO\n",
      "Already have QBL.AX\n",
      "Already have TSG.L\n",
      "Already have ATC.V\n",
      "Already have KGL.AX\n",
      "Already have TML.TO\n",
      "Already have IMA.AX\n",
      "Already have DRM.AX\n",
      "Already have RED.AX\n",
      "Already have MTO.V\n",
      "Already have DGR.AX\n",
      "Already have MRC.AX\n",
      "Already have DNG.TO\n",
      "Already have LIO.V\n",
      "Already have GME.AX\n",
      "Already have LEG.AX\n",
      "Already have BAR.TO\n",
      "Already have ATM.V\n",
      "Already have EAR.AX\n",
      "Already have KRM.AX\n",
      "Already have FML.AX\n",
      "Already have ORN.AX\n",
      "Already have ER.TO\n",
      "Already have RGD.V\n",
      "Already have RBX.V\n",
      "Already have LYD.TO\n",
      "Already have TXR.V\n",
      "Already have DEG.AX\n",
      "Already have TAM.AX\n",
      "Already have NGY.AX\n",
      "Already have CHN.AX\n",
      "Already have GRR.V\n",
      "Already have LG.V\n",
      "Already have GSR.V\n",
      "Already have TRY.AX\n",
      "Already have TNX.TO\n",
      "Already have TLM.AX\n",
      "Already have ME.TO\n",
      "Already have MJS.V\n",
      "Already have GCM.TO\n",
      "Already have BSR.AX\n",
      "Already have RTG.TO\n",
      "Already have CAY.AX\n",
      "Already have KTN.V\n",
      "Already have MRP.AX\n",
      "Already have ARE.AX\n",
      "Already have FSY.TO\n",
      "Already have TON.AX\n",
      "Already have SRB.L\n",
      "Already have BCN.AX\n",
      "Already have TSG.V\n",
      "Already have MAT.AX\n",
      "Already have IRC.AX\n",
      "Already have ERM.AX\n",
      "Already have ORV.TO\n",
      "Already have HMX.V\n",
      "Already have NGE.V\n",
      "Already have SPA.V\n",
      "Already have MAW.TO\n",
      "Already have MNR.TO\n",
      "Already have ANX.TO\n",
      "Already have SKE.V\n",
      "Already have AAU.L\n",
      "Already have WHY.V\n",
      "Already have NAG.AX\n",
      "Already have GRG.V\n",
      "Already have GQC.V\n",
      "Already have AAR.AX\n",
      "Already have AGC.V\n",
      "Already have HAW.AX\n",
      "Already have RUG.V\n",
      "Already have ECR.V\n",
      "Already have SIH.AX\n",
      "Already have SMC.AX\n",
      "Already have GLN.AX\n",
      "Already have GQM.TO\n",
      "Already have GDP.L\n",
      "Already have SAU.TO\n",
      "Already have MMV.V\n",
      "Already have GAL.V\n",
      "Already have MMY.V\n",
      "Already have CAS.AX\n",
      "Already have LPK.V\n",
      "Already have GWR.AX\n",
      "Already have REX.V\n",
      "Already have CLH.V\n",
      "Already have KG.V\n",
      "Already have AAB.TO\n",
      "Already have IAU.AX\n",
      "Already have AGG.V\n",
      "Already have BAR.AX\n",
      "Already have DRA.AX\n",
      "Already have OGR.V\n",
      "Already have AGD.V\n",
      "Already have DGO.AX\n",
      "Already have WDG.V\n",
      "Already have WKM.V\n",
      "Already have ANK.V\n",
      "Already have AZX.V\n",
      "Already have RRI.V\n",
      "Already have GWA.V\n",
      "Already have MC.V\n",
      "Already have BRZ.V\n",
      "Already have JPR.AX\n",
      "Already have CRB.AX\n",
      "Already have SWA.V\n",
      "Already have PJX.V\n",
      "Already have OOO.V\n",
      "Already have AZM.AX\n",
      "Already have AOM.AX\n",
      "Already have RDS.V\n",
      "Already have MUN.V\n",
      "Already have MDI.AX\n",
      "Already have MAE.V\n",
      "Already have TEN.V\n",
      "Already have HLX.AX\n",
      "Already have AGS.AX\n",
      "Already have LME.V\n",
      "Already have CTM.AX\n",
      "Already have RPX.V\n",
      "Already have MSR.AX\n",
      "Already have BAT.V\n",
      "Already have CTO.AX\n",
      "Already have MTU.V\n",
      "Already have RG.V\n",
      "Already have ECC.V\n",
      "Already have IO.V\n",
      "Already have GGA.TO\n",
      "                    NEM     ABX  FNV.TO  NCM.AX      GG    AEM    KGC   RGLD  \\\n",
      "marketCap        17.23B  15.03B  17.15B   15.7B   8.19B  8.15B  3.38B  4.79B   \n",
      "enterpriseValue  19.38B  21.11B  15.61B  16.95B  11.01B  9.54B  4.42B  5.15B   \n",
      "trailingPe            0       0   80.63   78.09  104.27  76.35  15.66      0   \n",
      "forwardPe         23.78   28.33   71.32   22.73   23.79  56.65  22.58  32.95   \n",
      "5YrPeg             6.64   -1.15    8.11    1.21   24.83  39.05  -3.61   1.31   \n",
      "\n",
      "                   RRS.L FRES.L  ...    CTM.AX   RPX.V  MSR.AX   BAT.V  \\\n",
      "marketCap          5.92B  5.55B  ...    16.13M  11.77M  10.57M   7.49M   \n",
      "enterpriseValue    5.71B  6.55B  ...    10.07M  10.83M   2.37M  -1.67M   \n",
      "trailingPe         24.29  11.52  ...         0       0       0       0   \n",
      "forwardPe        1848.97      0  ...         0       0       0       0   \n",
      "5YrPeg              2.69      0  ...         0       0       0       0   \n",
      "\n",
      "                 CTO.AX  MTU.V    RG.V   ECC.V    IO.V GGA.TO  \n",
      "marketCap         12.9M  4.61M  10.36M  10.97M  10.27M  8.33M  \n",
      "enterpriseValue  15.67M  4.46M  10.56M   2.58M  11.72M  9.33M  \n",
      "trailingPe         0.86      0       0       0       0  22.50  \n",
      "forwardPe             0      0       0       0       0      0  \n",
      "5YrPeg                0      0       0       0       0      0  \n",
      "\n",
      "[5 rows x 217 columns]\n"
     ]
    }
   ],
   "source": [
    "baseurl = \"https://uk.finance.yahoo.com/quote/\"\n",
    "\n",
    "def getDataFromYahoo(stockTypes, tickers, baseurl = baseurl):\n",
    "    \"\"\"Checks if data has been stored in csv, if not\n",
    "       looks to yahoo. Then returns as map of tickers to dataframe.\"\"\"\n",
    "    #Create directory for data of tickers.\n",
    "    dataDir = \"./%s_data\" % stockTypes\n",
    "    createDirIfItDoesntExist(dataDir)\n",
    "    \n",
    "    frames = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        dataFile = \"./%s/%s.csv\" % (dataDir, ticker)\n",
    "        data = None\n",
    "        if not os.path.exists(dataFile):\n",
    "            exists, data = saveDataAndReturnSeries(dataFile, ticker)\n",
    "            if not exists:\n",
    "                continue\n",
    "        else:\n",
    "            print(\"Already have %s\" % ticker)\n",
    "            data = pd.Series.from_csv(dataFile, index_col=0)\n",
    "        frames[ticker] = data\n",
    "    return pd.DataFrame(frames)\n",
    "\n",
    "def createDirIfItDoesntExist(dataDir):\n",
    "    \"\"\"If directory with name dataDir does not exist, create it.\"\"\"\n",
    "    if not os.path.exists(dataDir):\n",
    "        os.makedirs(dataDir)\n",
    "        \n",
    "def reformatData(data):\n",
    "    \"\"\"Reformat data with better names and remove redundancies\"\"\"\n",
    "    dataDict = {}\n",
    "    for index in wantedRows:\n",
    "        series = data.loc[index]\n",
    "        key = wantedRows[index]\n",
    "        value = series.get(1)\n",
    "        dataDict[key] = value\n",
    "    return pd.Series(dataDict)\n",
    "\n",
    "def getCurrency(html):\n",
    "    \"\"\"Gets the string of the currency stock is priced in.\"\"\"\n",
    "    soup = bs(html)\n",
    "    results = soup.findAll(\"span\", {\"data-reactid\" : \"9\"})\n",
    "    i = 0\n",
    "    for result in results:\n",
    "        if i == 1:\n",
    "            line = result.text\n",
    "        i += 1\n",
    "    return line[-3:] \n",
    "        \n",
    "def saveDataAndReturnSeries(dataFile, ticker):\n",
    "    \"\"\"Gets data from yahoo and dumps in csv file before \n",
    "       returning data as pandas series. Returns true, series if\n",
    "       there is data, false, none if not.\"\"\"\n",
    "    print(\"Requesting: %s\" % ticker)\n",
    "\n",
    "    #Go to summary page and scrape open.\n",
    "    priceData = requests.get(baseurl + \"%s?p=%s\" % (ticker, ticker))       \n",
    "    summaryFrames = pd.read_html(priceData.text)\n",
    "    summaryFrame = pd.concat(summaryFrames, ignore_index=True)\n",
    "    priceFrame = summaryFrame.loc[1:1]\n",
    "    \n",
    "    #Scrape currency from summary page.\n",
    "    currency = getCurrency(priceData.text)\n",
    "    \n",
    "    #Go to stats page and scrape stats.\n",
    "    data = requests.get(baseurl + \"%s/key-statistics?p=%s\" % (ticker, ticker))\n",
    "    frames = pd.read_html(data.text)\n",
    "    if len(frames) < 3:\n",
    "        print(\"No data for: %s\" % ticker)\n",
    "        return False , None\n",
    "\n",
    "    #Join stats and price\n",
    "    frames.append(priceFrame)\n",
    "    frame = pd.concat(frames, ignore_index=True)\n",
    "    \n",
    "    #Reformat\n",
    "    reformattedSeries = reformatData(frame)\n",
    "    reformattedSeries[\"currency\"] = currency.upper()\n",
    "    \n",
    "    #Save data\n",
    "    reformattedSeries.to_csv(dataFile)\n",
    "    return True, reformattedSeries\n",
    "\n",
    "tickerData = getDataFromYahoo(\"gold_stocks\", goldStockTickers)\n",
    "\n",
    "#Convert Nan values to 0.\n",
    "tickerData[pd.isnull(tickerData)] = \"0\"\n",
    "print(tickerData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reformat text rows into numbers for numerical analysis.\n",
    "\n",
    "Use maps defined earlier to create masks and apply conversion functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   NEM    ABX FNV.TO NCM.AX      GG    AEM    KGC   RGLD  \\\n",
      "marketCap        17230  15030  17150  15700    8190   8150   3380   4790   \n",
      "enterpriseValue  19380  21110  15610  16950   11010   9540   4420   5150   \n",
      "trailingPe           0      0  80.63  78.09  104.27  76.35  15.66      0   \n",
      "forwardPe        23.78  28.33  71.32  22.73   23.79  56.65  22.58  32.95   \n",
      "5YrPeg            6.64  -1.15   8.11   1.21   24.83  39.05  -3.61   1.31   \n",
      "\n",
      "                   RRS.L FRES.L  ...   CTM.AX  RPX.V MSR.AX BAT.V CTO.AX  \\\n",
      "marketCap           5920   5550  ...    16.13  11.77  10.57  7.49   12.9   \n",
      "enterpriseValue     5710   6550  ...    10.07  10.83   2.37 -1.67  15.67   \n",
      "trailingPe         24.29  11.52  ...        0      0      0     0   0.86   \n",
      "forwardPe        1848.97      0  ...        0      0      0     0      0   \n",
      "5YrPeg              2.69      0  ...        0      0      0     0      0   \n",
      "\n",
      "                MTU.V   RG.V  ECC.V   IO.V GGA.TO  \n",
      "marketCap        4.61  10.36  10.97  10.27   8.33  \n",
      "enterpriseValue  4.46  10.56   2.58  11.72   9.33  \n",
      "trailingPe          0      0      0      0  22.50  \n",
      "forwardPe           0      0      0      0      0  \n",
      "5YrPeg              0      0      0      0      0  \n",
      "\n",
      "[5 rows x 217 columns]\n"
     ]
    }
   ],
   "source": [
    "def convertLetter(string):\n",
    "    if string == \"0\":\n",
    "        return 0\n",
    "    string = string.replace(\",\", \"\")\n",
    "    number = string[0:-1]\n",
    "    letter = string[-1]\n",
    "    if letter == \"B\":\n",
    "        return float(number) * 1000\n",
    "    if letter == \"M\":\n",
    "        return float(number) \n",
    "    if letter == \"k\":\n",
    "        return float(number) / 100\n",
    "    \n",
    "def convertPercent(string):\n",
    "    if string == \"0\":\n",
    "        return 0\n",
    "    string = string.replace(\",\", \"\")\n",
    "    number = string[0:-1]\n",
    "    return float(number)\n",
    "\n",
    "# Create mask for letter numbers and convert them.\n",
    "letterMask = tickerData.index.isin(letterNumbers)\n",
    "tickerData[letterMask] = tickerData[letterMask].applymap(convertLetter)\n",
    "\n",
    "# Create mask for percentage numbers and convert them.\n",
    "percentageMask = tickerData.index.isin(percentageNumbers)\n",
    "tickerData[percentageMask] = tickerData[percentageMask].applymap(convertPercent)\n",
    "\n",
    "print(tickerData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Now normalize for currencies.\n",
    "\n",
    "Companies stock is denominated in different currencies, we must normalise for good aggregations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use api to look up fx rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USD': 1.0, 'AUD': 0.7363037819827888, 'CAD': 0.7572743133536014, 'GBP': 1.2779797157323411, 'EUR': 1.136331}\n"
     ]
    }
   ],
   "source": [
    "fxurl = \"http://data.fixer.io/api/latest?access_key=d76b170eea08be26f92b73f07d9a7cad&symbols=USD,AUD,CAD,GBP,EUR\"\n",
    "r = requests.get(fxurl)\n",
    "r = json.loads(r.text)\n",
    "rates = r[\"rates\"]\n",
    "usdFactor = rates[\"USD\"]\n",
    "for c in rates:\n",
    "    rates[c] = 1 / (rates[c] / usdFactor)\n",
    "print(rates)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must specify which companies, ie columns, are not denominated in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonDollarDenominated = (tickerData.loc[\"currency\"] != \"USD\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify which rows need to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currencyConcerned = [\"marketCap\", \n",
    "                     \"enterpriseValue\",\n",
    "                     \"revenue\",\n",
    "                     \"grossProfit\",\n",
    "                     \"EBITDA\",\n",
    "                     \"netIncomeForCommon\",\n",
    "                     \"totalCash\",\n",
    "                     \"totalDebt\",\n",
    "                     \"operatingCashFlow\",\n",
    "                     \"leveredFreeCashFlow\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (tickerData.loc[\"marketCap\"] > 5000) & (tickerData.loc[\"revenue\"] > 10)\n",
    "tickerData.loc[:, mask.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
